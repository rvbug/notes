"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[6637],{5059:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>i,metadata:()=>a,toc:()=>s});var a=r(1888),t=r(4848),d=r(8453);const i={slug:"PTXIntro",title:"PTX Basics",authors:["rakesh"],tags:["ML","ML Research"]},l="Introduction",o={authorsImageUrls:[void 0]},s=[{value:"<strong>Basic Structure</strong>",id:"basic-structure",level:2},{value:"<strong>Registers</strong>",id:"registers",level:2},{value:"<strong>Instructions</strong>",id:"instructions",level:2},{value:"<strong>Memory Operations</strong>",id:"memory-operations",level:2},{value:"<strong>Special Registers</strong>",id:"special-registers",level:2},{value:"<strong>Math Operaations</strong>",id:"math-operaations",level:2},{value:"<strong>Tensor Core Operations</strong>",id:"tensor-core-operations",level:2},{value:"<strong>Control Flow</strong>",id:"control-flow",level:2},{value:"Code Sample",id:"code-sample",level:2},{value:"Generating output",id:"generating-output",level:3},{value:"Code Explaination",id:"code-explaination",level:3},{value:"Kernel Function",id:"kernel-function",level:4},{value:"Main function",id:"main-function",level:4},{value:"GPU Memory Allocation",id:"gpu-memory-allocation",level:4},{value:"GPU Data Transfer",id:"gpu-data-transfer",level:4},{value:"Kernel Launch Configuration",id:"kernel-launch-configuration",level:4},{value:"Results and Cleanup",id:"results-and-cleanup",level:4},{value:"PTX Code",id:"ptx-code",level:2},{value:"PTX file",id:"ptx-file",level:3},{value:"PTX Code",id:"ptx-code-1",level:3},{value:"Entry Point",id:"entry-point",level:3},{value:"Register Declaration",id:"register-declaration",level:3},{value:"Parameter Loading",id:"parameter-loading",level:3},{value:"Thread ID",id:"thread-id",level:3},{value:"Bounds Checking",id:"bounds-checking",level:3},{value:"Memory Calculations",id:"memory-calculations",level:3},{value:"Load, Add and Store",id:"load-add-and-store",level:3},{value:"Return from Kernel",id:"return-from-kernel",level:3}];function c(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,d.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:"Parallel Thread Execution (PTX) is a virtual machine instruction set architecture and can be thought of as the assembly language for NVDIA GPUs"}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h1,{id:"ptx-syntax",children:"PTX Syntax"}),"\n",(0,t.jsx)(n.p,{children:"Here are few syntax of PTX for your references."}),"\n",(0,t.jsx)(n.h2,{id:"basic-structure",children:(0,t.jsx)(n.strong,{children:"Basic Structure"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:".version 7.0                    // PTX version\n.target sm_70                   // Target architecture\n.address_size 64                // 64-bit addressing\n\n.visible .entry kernel_name(   // Kernel name and declaration\n    .param .u64 param1,        // Parameters\n    .param .f32 param2\n)\n{\n    // Kernel body\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"registers",children:(0,t.jsx)(n.strong,{children:"Registers"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:".reg .b32 %r<5>;    // 5 32-bit registers %r0 through %r4\n.reg .f32 %f<3>;    // 3 single-precision float\n.reg .b64 %rd<2>;   // 2 64-bit \n.reg .pred %p<2>;   // 2 predicate registers (conditionals)\n\n"})}),"\n",(0,t.jsx)(n.h2,{id:"instructions",children:(0,t.jsx)(n.strong,{children:"Instructions"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:"mov.u32 %r1, %tid.x;       // Move thread(ID) to %r1\nadd.s32 %r3, %r1, %r2;     // Add int\nmul.f32 %f3, %f1, %f2;     // Mul floats\nsetp.lt.s32 %p1, %r1, %r2; // Set predicate if r1 < r2\n@%p1 bra label;            // Conditional branch\n\n"})}),"\n",(0,t.jsx)(n.h2,{id:"memory-operations",children:(0,t.jsx)(n.strong,{children:"Memory Operations"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:"ld.param.u64 %rd1, [param1];       // Load param into register\nld.global.f32 %f1, [%rd1];         // Load from global mem\nst.global.f32 [%rd2], %f2;         // Store to global mem\nld.shared.f32 %f3, [%rd3];         // Load from shared mem\nld.global.v4.f16 {%f1, %f2, %f3, %f4}, [%rd1];  // Vector load\n\n"})}),"\n",(0,t.jsx)(n.h2,{id:"special-registers",children:(0,t.jsx)(n.strong,{children:"Special Registers"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:"%tid.x, %tid.y, %tid.z     // Thread (ID) within a block\n%ctaid.x, %ctaid.y, %ctaid.z   // Block (ID) within a grid\n%ntid.x, %ntid.y, %ntid.z  // Block dimensions (threads per block)\n\n"})}),"\n",(0,t.jsx)(n.h2,{id:"math-operaations",children:(0,t.jsx)(n.strong,{children:"Math Operaations"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:"add.f32 %f3, %f1, %f2;     // Add\nsub.f32 %f3, %f1, %f2;     // Sub\nmul.f32 %f3, %f1, %f2;     // Mul\ndiv.f32 %f3, %f1, %f2;     // Div\nmad.f32 %f4, %f1, %f2, %f3;  // Multiply & add: (f4 = f1*f2+f3)\n"})}),"\n",(0,t.jsx)(n.h2,{id:"tensor-core-operations",children:(0,t.jsx)(n.strong,{children:"Tensor Core Operations"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:"// Matrix multiply-accumulate using tensor cores\nmma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16 \n    {%f5, %f6, %f7, %f8},   // Destination registers\n    {%f1, %f2},             // A matrix registers\n    {%f3, %f4},             // B matrix registers\n    {%f5, %f6, %f7, %f8};   // C matrix registers (accumulator)\n\n"})}),"\n",(0,t.jsx)(n.h2,{id:"control-flow",children:(0,t.jsx)(n.strong,{children:"Control Flow"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:"bra label;           // Unconditional branch\n@%p1 bra label;      // Conditional branch if predicate = true\nret;                 // Return from kernel\n"})}),"\n",(0,t.jsx)(n.h2,{id:"code-sample",children:"Code Sample"}),"\n",(0,t.jsx)(n.p,{children:"Now that we know the the basic syntax of PTX, here is one simple rust program for vector addition."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-C",children:"\n#include <stdio.h>\n#include <cuda.h>\n#include <cuda_runtime.h>\n\n// Kernel function to add the elements of two arrays\n__global__ void vectorAdd(int *a, int *b, int *c, int n) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < n) {\n        c[i] = a[i] + b[i];\n    }\n}\n\nint main() {\n    int n = 1000;\n    int size = n * sizeof(int);\n    int *a, *b, *c;\n    int *d_a, *d_b, *d_c;\n\n    // Allocate memory on the host\n    a = (int *)malloc(size);\n    b = (int *)malloc(size);\n    c = (int *)malloc(size);\n\n    // Initialize the arrays\n    for (int i = 0; i < n; i++) {\n        a[i] = i;\n        b[i] = i * 2;\n    }\n\n    // Allocate memory on the device\n    cudaMalloc((void **)&d_a, size);\n    cudaMalloc((void **)&d_b, size);\n    cudaMalloc((void **)&d_c, size);\n\n    // Copy data from host to device\n    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n\n    // Launch the vectorAdd kernel\n    int threadsPerBlock = 256;\n    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n\n    // Copy the result from device to host\n    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n\n    // Free device memory\n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    // Free host memory\n    free(a);\n    free(b);\n    free(c);\n\n    return 0;\n}\n\n"})}),"\n",(0,t.jsx)(n.h3,{id:"generating-output",children:"Generating output"}),"\n",(0,t.jsxs)(n.p,{children:["Let us compile the code using ",(0,t.jsx)(n.code,{children:"nvcc"})," compiler"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"$> nvcc vector.cu -o vector\n$> ./my_kernel\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# output\nc[0] = 0\nc[1] = 3\nc[2] = 6\nc[3] = 9\nc[4] = 12\nc[5] = 15\nc[6] = 18\nc[7] = 21\nc[8] = 24\nc[9] = 27\n\n"})}),"\n",(0,t.jsx)(n.h3,{id:"code-explaination",children:"Code Explaination"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-C",children:"// This is for CUDA runtime functions\n#include <cuda_runtime.h> \n"})}),"\n",(0,t.jsx)(n.h4,{id:"kernel-function",children:"Kernel Function"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.em,{children:(0,t.jsx)(n.code,{children:"__global__"})})," specifices that this is CUDA kernel that runs on GPU"]}),"\n",(0,t.jsxs)(n.li,{children:["Three float arrays are pointers along with array size  ",(0,t.jsx)(n.code,{children:"a"}),", ",(0,t.jsx)(n.code,{children:"b"})," and ",(0,t.jsx)(n.code,{children:"c"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.em,{children:(0,t.jsx)(n.code,{children:"blockIdx.x"})})," is the block index."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.em,{children:(0,t.jsx)(n.code,{children:"blockDim.x"})})," is number of thread per block"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.em,{children:(0,t.jsx)(n.code,{children:"threadIdx.x"})})," is thread index within a block"]}),"\n",(0,t.jsx)(n.li,{children:"Calculate unique ID for each thread to process a different array element"}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-C",children:"// CUDA kernel for vector addition\n__global__ void vectorAdd(float *a, float *b, float *c, int n)\n{\n    // Calculate global thread ID\n    int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n    // To make sure we don't go out of bounds\n    if (id < n)\n        c[id] = a[id] + b[id];\n}\n"})}),"\n",(0,t.jsx)(n.h4,{id:"main-function",children:"Main function"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-C",children:"int main()\n{\n    // Vector size\n    int n = 1000000;               // One million elements\n    size_t bytes = n * sizeof(float);  // Calculate memory size in bytes\n    // Allocate host memory\n    float *h_a = (float*)malloc(bytes);  // Allocate memory for array a\n    float *h_b = (float*)malloc(bytes);  // Allocate memory for array b\n    float *h_c = (float*)malloc(bytes);  // Allocate memory for results\n    // Initialize vectors on host\n    for (int i = 0; i < n; i++)\n    {\n        h_a[i] = 1.0f;  // All elements in a are 1.0\n        h_b[i] = 2.0f;  // All elements in b are 2.0\n    }\n}\n"})}),"\n",(0,t.jsx)(n.h4,{id:"gpu-memory-allocation",children:"GPU Memory Allocation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-C",children:"// Allocate device memory\n    float *d_a, *d_b, *d_c;            // Declare device pointers\n    cudaMalloc(&d_a, bytes);           // Allocate memory on GPU for a\n    cudaMalloc(&d_b, bytes);           // Allocate memory on GPU for b\n    cudaMalloc(&d_c, bytes);           // Allocate memory on GPU for c\n\n"})}),"\n",(0,t.jsx)(n.h4,{id:"gpu-data-transfer",children:"GPU Data Transfer"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-C",children:"// Copy data from host to device\n    cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice);  // Copy a to GPU\n    cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice);  // Copy b to GPU\n\n"})}),"\n",(0,t.jsx)(n.h4,{id:"kernel-launch-configuration",children:"Kernel Launch Configuration"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-C",children:"// Set up execution configuration\n    int blockSize = 256;                         // 256 threads per block\n    int gridSize = (n + blockSize - 1) / blockSize;  // Calculate grid size\n// This formula ensures we have enough blocks to cover all elements\n// Launch kernel\n    vectorAdd<<<gridSize, blockSize>>>(d_a, d_b, d_c, n);\n    // <<<>>> is special CUDA syntax for kernel launch configuration\n    // gridSize = number of blocks, blockSize = threads per block\n"})}),"\n",(0,t.jsx)(n.h4,{id:"results-and-cleanup",children:"Results and Cleanup"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-C",children:"// Copy result back to host\ncudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);  // Copy results from GPU to CPU\n\n// Free memory\ncudaFree(d_a);  // Free GPU memory for a\ncudaFree(d_b);  // Free GPU memory for b\ncudaFree(d_c);  // Free GPU memory for c\nfree(h_a);      // Free CPU memory for a\nfree(h_b);      // Free CPU memory for b\nfree(h_c);      // Free CPU memory for c\n\n"})}),"\n",(0,t.jsx)(n.h2,{id:"ptx-code",children:"PTX Code"}),"\n",(0,t.jsx)(n.p,{children:"To extract PTX  from the above code, try this the following command."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"$> nvcc -ptx vector.cu -o vector.ptx\n"})}),"\n",(0,t.jsx)(n.h3,{id:"ptx-file",children:"PTX file"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:"\n.visible .entry vectorAdd(\n    .param .u64 vectorAdd_param_0,  // Pointer to array a\n    .param .u64 vectorAdd_param_1,  // Pointer to array b\n    .param .u64 vectorAdd_param_2,  // Pointer to array c\n    .param .u32 vectorAdd_param_3   // Parameter n (size)\n)\n{\n    .reg .pred  %p<2>;          // Predicate registers\n    .reg .f32   %f<4>;          // Float registers\n    .reg .b32   %r<6>;          // 32-bit registers\n    .reg .b64   %rd<11>;        // 64-bit registers\n\n    // Load parameters into registers\n    ld.param.u64    %rd1, [vectorAdd_param_0];\n    ld.param.u64    %rd2, [vectorAdd_param_1];\n    ld.param.u64    %rd3, [vectorAdd_param_2];\n    ld.param.u32    %r2, [vectorAdd_param_3];\n    \n    // Calculate thread ID\n    mov.u32         %r3, %ctaid.x;    // Get block index\n    mov.u32         %r4, %ntid.x;     // Get block size\n    mov.u32         %r5, %tid.x;      // Get thread index within block\n    mad.lo.s32      %r1, %r3, %r4, %r5;  // Calculate global thread ID: blockIdx * blockDim + threadIdx\n    \n    // Check if thread ID is within bounds\n    setp.ge.s32     %p1, %r1, %r2;    // Set predicate if thread ID >= n\n    @%p1 bra        BB0_2;            // If true, jump to the end (BB0_2 label)\n    \n    // Calculate memory addresses\n    cvta.to.global.u64  %rd4, %rd1;   // Convert array a pointer to global address\n    mul.wide.s32    %rd5, %r1, 4;     // Multiply thread ID by 4 (size of float)\n    add.s64         %rd6, %rd4, %rd5; // Calculate address for a[id]\n    \n    cvta.to.global.u64  %rd7, %rd2;   // Convert array b pointer to global address\n    add.s64         %rd8, %rd7, %rd5; // Calculate address for b[id]\n    \n    // Load values, add them, and store result\n    ld.global.f32   %f1, [%rd6];      // Load a[id]\n    ld.global.f32   %f2, [%rd8];      // Load b[id]\n    add.f32         %f3, %f1, %f2;    // Add them: c[id] = a[id] + b[id]\n    \n    cvta.to.global.u64  %rd9, %rd3;   // Convert array c pointer to global address\n    add.s64         %rd10, %rd9, %rd5; // Calculate address for c[id]\n    st.global.f32   [%rd10], %f3;     // Store the result in c[id]\n    \nBB0_2:                                // End label\n    ret;                              // Return from kernel\n}\n\n"})}),"\n",(0,t.jsx)(n.h3,{id:"ptx-code-1",children:"PTX Code"}),"\n",(0,t.jsx)(n.p,{children:"Let us now review the PTX code"}),"\n",(0,t.jsx)(n.h3,{id:"entry-point",children:"Entry Point"}),"\n",(0,t.jsx)(n.p,{children:"This section declares entry point for the kernel followed by 4 paramaters which is a pointer to the variable a, b, c and size n."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:"\n.visible .entry vectorAdd(           // Declares entry point for kernel\n    .param .u64 vectorAdd_param_0,   // First parameter (pointer to array a)\n    .param .u64 vectorAdd_param_1,   // Second parameter (pointer to array b)\n    .param .u64 vectorAdd_param_2,   // Third parameter (pointer to array c)\n    .param .u32 vectorAdd_param_3    // Fourth parameter (size n)\n)\n\n"})}),"\n",(0,t.jsx)(n.h3,{id:"register-declaration",children:"Register Declaration"}),"\n",(0,t.jsx)(n.p,{children:"Declating Predicate registers for conditions, float registers, 32 bit int and register for addresses"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:"    .reg .pred  %p<2>;          // Predicate r\n    .reg .f32   %f<4>;          // Float \n    .reg .b32   %r<6>;          // 32-bit int\n    .reg .b64   %rd<11>;        // 64-bit for addresses\n"})}),"\n",(0,t.jsx)(n.h3,{id:"parameter-loading",children:"Parameter Loading"}),"\n",(0,t.jsxs)(n.p,{children:["This section loads parameters from kernel into registers. ",(0,t.jsx)(n.code,{children:"ld"})," is for load."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:"\n    ld.param.u64    %rd1, [vectorAdd_param_0];  // Load pointer to array a\n    ld.param.u64    %rd2, [vectorAdd_param_1];  // Load pointer to array b\n    ld.param.u64    %rd3, [vectorAdd_param_2];  // Load pointer to array c\n    ld.param.u32    %r2, [vectorAdd_param_3];   // Load size n\n"})}),"\n",(0,t.jsx)(n.h3,{id:"thread-id",children:"Thread ID"}),"\n",(0,t.jsx)(n.p,{children:"Now calcuate unique thread Id using built-on registers."}),"\n",(0,t.jsxs)(n.p,{children:["First get the current block index into ",(0,t.jsx)(n.code,{children:"%r3"}),", then get number of threads per block into ",(0,t.jsx)(n.code,{children:"%r4"})," and then get thread index within this block into ",(0,t.jsx)(n.code,{children:"%r5"}),". ",(0,t.jsx)(n.code,{children:"mad"})," is multiply and add in a single instruction and calculate ID by using ",(0,t.jsx)(n.code,{children:"blockIdx * blockDim + threadIdx"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:"    mov.u32         %r3, %ctaid.x;    \n    mov.u32         %r4, %ntid.x;     \n    mov.u32         %r5, %tid.x;      \n    mad.lo.s32      %r1, %r3, %r4, %r5; \n"})}),"\n",(0,t.jsx)(n.h3,{id:"bounds-checking",children:"Bounds Checking"}),"\n",(0,t.jsxs)(n.p,{children:["Here we check  if thread ID is within bounds of the array and then Set predicate ",(0,t.jsx)(n.code,{children:"%p1"})," if thread ID >= n. If true then jump to return label ",(0,t.jsx)(n.code,{children:"BB0_2"})]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:"// \nsetp.ge.s32     %p1, %r1, %r2;    // \n@%p1 bra        BB0_2;            // If true, jump to the return label (BB0_2)\n\n"})}),"\n",(0,t.jsx)(n.h3,{id:"memory-calculations",children:"Memory Calculations"}),"\n",(0,t.jsxs)(n.p,{children:["Calculate memory address for array elements. Covert array ",(0,t.jsx)(n.code,{children:"a"})," pointer to global address using ",(0,t.jsx)(n.code,{children:"cvta"}),".  Multiply ",(0,t.jsx)(n.code,{children:"mul"})," thread Id by 4 which is the size of the float followed by adding address for ",(0,t.jsx)(n.code,{children:"a"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:"\n    cvta.to.global.u64  %rd4, %rd1;   \n    mul.wide.s32    %rd5, %r1, 4;     \n    add.s64         %rd6, %rd4, %rd5; \n    \n    cvta.to.global.u64  %rd7, %rd2;   // Convert array b pointer to global address\n    add.s64         %rd8, %rd7, %rd5; // Calculate address for b[id]\n\n"})}),"\n",(0,t.jsx)(n.h3,{id:"load-add-and-store",children:"Load, Add and Store"}),"\n",(0,t.jsx)(n.p,{children:"Load values from arrays, perform addition, and store result"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:"    ld.global.f32   %f1, [%rd6];      // Load a[id] into register %f1\n    ld.global.f32   %f2, [%rd8];      // Load b[id] into register %f2\n    add.f32         %f3, %f1, %f2;    // Add them: %f3 = %f1 + %f2\n    \n    cvta.to.global.u64  %rd9, %rd3;   // Convert array c pointer to global address\n    add.s64         %rd10, %rd9, %rd5; // Calculate address for c[id]\n    st.global.f32   [%rd10], %f3;     // Store the result in c[id]\n\n"})}),"\n",(0,t.jsx)(n.h3,{id:"return-from-kernel",children:"Return from Kernel"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ptx",children:"BB0_2:  // Label for our return point\nret;                             \n"})})]})}function h(e={}){const{wrapper:n}={...(0,d.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>i,x:()=>l});var a=r(6540);const t={},d=a.createContext(t);function i(e){const n=a.useContext(d);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),a.createElement(d.Provider,{value:n},e.children)}},1888:e=>{e.exports=JSON.parse('{"permalink":"/notes/blog/PTXIntro","source":"@site/blog/2025-03-01/2. Intro_to_ptx.md","title":"PTX Basics","description":"Parallel Thread Execution (PTX) is a virtual machine instruction set architecture and can be thought of as the assembly language for NVDIA GPUs","date":"2025-03-01T00:00:00.000Z","tags":[{"inline":true,"label":"ML","permalink":"/notes/blog/tags/ml"},{"inline":true,"label":"ML Research","permalink":"/notes/blog/tags/ml-research"}],"readingTime":9.19,"hasTruncateMarker":true,"authors":[{"name":"rakesh","title":"Sr. Engineering Manager","url":"https://qubitai.in","page":{"permalink":"/notes/blog/authors/rakesh"},"socials":{"w":"https://qubitai.in","github":"https://github.com/rvbug"},"imageURL":"https://avatars.githubusercontent.com/u/10928536?v=4","key":"rakesh"}],"frontMatter":{"slug":"PTXIntro","title":"PTX Basics","authors":["rakesh"],"tags":["ML","ML Research"]},"unlisted":false,"prevItem":{"title":"Graphics Processing Unit (GPU)","permalink":"/notes/blog/GPU"},"nextItem":{"title":"PTX Optimization","permalink":"/notes/blog/DeepSeekPTX"}}')}}]);