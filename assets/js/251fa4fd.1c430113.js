"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[9264],{3793:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>r,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>l});var t=i(9851),s=i(4848),o=i(8453);const a={slug:"Tokenizer",title:"Tokenization",description:"What is Tokenizer",authors:["rakesh"],tags:["ML","ML Research"]},r="Introduction",d={authorsImageUrls:[void 0]},l=[{value:"Types of Tokenizer",id:"types-of-tokenizer",level:2},{value:"Byte Pair Encoding (BPE)",id:"byte-pair-encoding-bpe",level:2},{value:"Modified BPE",id:"modified-bpe",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"In building LLMs, the first step is to obtain the input text and pass it through the Tokenizer"}),"\n",(0,s.jsx)(n.h1,{id:"tokenizer",children:"Tokenizer"}),"\n",(0,s.jsx)(n.p,{children:"Steps in Tokenization is as follows"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Tokenization",src:i(4661).A+"",width:"1720",height:"644"})}),"\n",(0,s.jsx)(n.h2,{id:"types-of-tokenizer",children:"Types of Tokenizer"}),"\n",(0,s.jsx)(n.p,{children:"Below are three type of Tokenizers available."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"alt text",src:i(1261).A+"",width:"2398",height:"1131"})}),"\n",(0,s.jsx)(n.h2,{id:"byte-pair-encoding-bpe",children:"Byte Pair Encoding (BPE)"}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Orginally BPE was developed as a compression algorithm."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Checkout more details and the example used from ",(0,s.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Byte_pair_encoding",children:(0,s.jsx)(n.strong,{children:"Wiki"})})]}),"\n"]}),"\n"]})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"alt text",src:i(9857).A+"",width:"1902",height:"1414"})}),"\n",(0,s.jsx)(n.h2,{id:"modified-bpe",children:"Modified BPE"}),"\n",(0,s.jsx)(n.admonition,{type:"tip",children:(0,s.jsxs)(n.p,{children:["In LLM, we use something called ",(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"Modified Byte Pair Encoding"})}),". Used for encoding plain text to tokens"]})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"alt text",src:i(3310).A+"",width:"1949",height:"965"})})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},9857:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/Bpe-87b63a28e01d14a66bd9be25d22fd45f.png"},3310:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/ModifiedBPE-ed3fd7fb8aeeb937be137de1b7a8b469.png"},4661:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/tokenization-84b99bbcfbde166c43fe4ffe46cc2c9a.png"},1261:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/tokenizer-ae00bc46580d95c23e2f3998d6a35dfb.png"},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>r});var t=i(6540);const s={},o=t.createContext(s);function a(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(o.Provider,{value:n},e.children)}},9851:e=>{e.exports=JSON.parse('{"permalink":"/notes/blog/Tokenizer","source":"@site/blog/2025-03-01/4.Tokenization.md","title":"Tokenization","description":"What is Tokenizer","date":"2025-03-01T00:00:00.000Z","tags":[{"inline":false,"label":"ML","permalink":"/notes/blog/tags/ML","description":"Machine Learning"},{"inline":false,"label":"ML Reserach","permalink":"/notes/blog/tags/ML-Research","description":"Machine Learning Research"}],"readingTime":0.475,"hasTruncateMarker":true,"authors":[{"name":"rakesh","title":"Sr. Engineering Manager","url":"https://qubitai.in","page":{"permalink":"/notes/blog/authors/rakesh"},"socials":{"w":"https://qubitai.in","github":"https://github.com/rvbug"},"imageURL":"https://avatars.githubusercontent.com/u/10928536?v=4","key":"rakesh"}],"frontMatter":{"slug":"Tokenizer","title":"Tokenization","description":"What is Tokenizer","authors":["rakesh"],"tags":["ML","ML Research"]},"unlisted":false,"prevItem":{"title":"PTX Optimization","permalink":"/notes/blog/DeepSeekPTX"},"nextItem":{"title":"Dotfiles","permalink":"/notes/blog/dotfiles"}}')}}]);